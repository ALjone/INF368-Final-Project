{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEvkHKWV71ua",
    "outputId": "4a527e9c-3c05-49f8-aad3-d4f26b384928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement official.nlp (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for official.nlp\u001b[0m\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.19.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "#! git clone https://github.com/ALjone/INF368-Final-Project\n",
    "\n",
    "# A dependency of the preprocessing for BERT inputs\n",
    "!pip install -q -U tensorflow-text\n",
    "!pip install -q tf-models-official\n",
    "\n",
    "!pip install -q tensorflow\n",
    "!pip install -q tensorflow_hub\n",
    "\n",
    "!pip install -q official.nlp\n",
    "\n",
    "\n",
    "!pip install -q matplotlib\n",
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KStEf5aqwXQz"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.chdir('..')\n",
    "from Bert import Bert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up\n",
    "\n",
    "Set gloabal variable for changing dataset.\n",
    "\n",
    "Set data_name to the name of your dataset. This needs to correspond to a folder in /data/, which should be generated by the generate_data.ipynb notebook. num_classes manually needs to be set to the number of classes in your dataset.\n",
    "\n",
    "- data_name: \"imdb\" or \"medical\"\n",
    "- num_classes:\n",
    "    - imdb: 2\n",
    "    - medical: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YycaUlL17829"
   },
   "outputs": [],
   "source": [
    "## gloabal variable for changing dataset.\n",
    "## data_name possible values: \"imdb\", \"medical\"\n",
    "data_name = \"medical\"\n",
    "## num_classes possible values: \"imdb\"=2, \"medical\"=5\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data paths\n",
    "- Get the file path for training data sets, 5, 10, 25, and 50 per label\n",
    "- Get the path for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the path for the training data sets, 5, 10, 25, and 50 per label\n",
    "data_path = 'data/'+data_name\n",
    "files = os.listdir(data_path)\n",
    "labeled_files = [data_path+\"/\"+file for file in files if \"train_labeled\" in file]\n",
    "\n",
    "## get the path for the test set\n",
    "test_path = data_path+\"/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyper-parameters for Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IgGLg_kOxhg3"
   },
   "outputs": [],
   "source": [
    "# hyper parameters \n",
    "batch_size = 4\n",
    "seed = 0\n",
    "learning_rate = 5e-5\n",
    "epochs=5\n",
    "\n",
    "# create a data frame to store the results\n",
    "results=pd.DataFrame(columns=[\"n_per_class\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning and evalueate the Bert classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xITIE4h-5NO",
    "outputId": "05d1ac3a-8a14-45c8-adfe-aa60d6fb9df6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 19:36:54.988275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10800 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7\n",
      "2021-11-11 19:36:58.084455: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/medical/train_labeled_5.csv\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 22s 269ms/step - loss: 1.5570 - accuracy: 0.3600\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 2s 262ms/step - loss: 1.0369 - accuracy: 0.6000\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 2s 265ms/step - loss: 1.1334 - accuracy: 0.6000\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 2s 262ms/step - loss: 0.9176 - accuracy: 0.7600\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 2s 261ms/step - loss: 0.8068 - accuracy: 0.7200\n",
      "500/500 [==============================] - 18s 33ms/step - loss: 0.9731 - accuracy: 0.6000\n",
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n",
      "data/medical/train_labeled_10.csv\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 23s 278ms/step - loss: 2.0240 - accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 4s 272ms/step - loss: 1.4455 - accuracy: 0.4000\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 4s 273ms/step - loss: 1.1934 - accuracy: 0.4600\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 4s 275ms/step - loss: 0.8327 - accuracy: 0.7600\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 4s 274ms/step - loss: 0.6555 - accuracy: 0.8600\n",
      "500/500 [==============================] - 18s 33ms/step - loss: 1.7167 - accuracy: 0.2740\n",
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n",
      "data/medical/train_labeled_25.csv\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - 28s 278ms/step - loss: 1.2559 - accuracy: 0.4880\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 9s 277ms/step - loss: 0.9699 - accuracy: 0.5920\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.7226 - accuracy: 0.7120\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.4782 - accuracy: 0.8160\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.2463 - accuracy: 0.8880\n",
      "500/500 [==============================] - 18s 33ms/step - loss: 1.4256 - accuracy: 0.5620\n",
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n",
      "data/medical/train_labeled_50.csv\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 37s 279ms/step - loss: 1.5747 - accuracy: 0.3200\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 280ms/step - loss: 1.3896 - accuracy: 0.3600\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 280ms/step - loss: 1.0450 - accuracy: 0.5520\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 280ms/step - loss: 0.4800 - accuracy: 0.8440\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 281ms/step - loss: 0.1538 - accuracy: 0.9600\n",
      "500/500 [==============================] - 18s 34ms/step - loss: 1.5763 - accuracy: 0.5200\n"
     ]
    }
   ],
   "source": [
    "## train and evaluate bert for each data set. \n",
    "for n_per_class in [5,10,25,50]:\n",
    "    data_file = \"\"\n",
    "    result = {\"n_per_class\":n_per_class}\n",
    "    bert = Bert(num_classes = num_classes, random_state = seed) # create model \n",
    "    for file in labeled_files: ## find correct file\n",
    "        if f\"train_labeled_{n_per_class}.csv\" in file:\n",
    "            data_file = file\n",
    "            break\n",
    "    print(data_file)\n",
    "    ## train model\n",
    "    bert.train_from_path(data_file,learning_rate=learning_rate,batch_size=batch_size,epochs=epochs)\n",
    "    ## evaluate the model\n",
    "    performance = bert.evaluate_from_path(test_path)\n",
    "    ## add to resutl data frame\n",
    "    result[\"accuracy\"] = performance[1]\n",
    "    results = results.append(result,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "LZGVYA2GcoCU",
    "outputId": "8dc78616-4d26-4fa2-d406-41172b439228"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_per_class</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_per_class  accuracy\n",
       "0          5.0     0.600\n",
       "1         10.0     0.274\n",
       "2         25.0     0.562\n",
       "3         50.0     0.520"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print the result\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gZNtDZIgDXhw"
   },
   "outputs": [],
   "source": [
    "# write the result to file\n",
    "if not os.path.exists('results'):\n",
    "      os.mkdir('results')\n",
    "result_path = f'results/{data_name}'\n",
    "if not os.path.exists(result_path):\n",
    "      os.mkdir(result_path)\n",
    "results.to_csv(f\"{result_path}/bert_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
