{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEvkHKWV71ua",
    "outputId": "4a527e9c-3c05-49f8-aad3-d4f26b384928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.19.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "#! git clone https://github.com/ALjone/INF368-Final-Project\n",
    "\n",
    "# A dependency of the preprocessing for BERT inputs\n",
    "!pip install -q -U tensorflow-text\n",
    "!pip install -q tf-models-official\n",
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KStEf5aqwXQz"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.chdir('..')\n",
    "from Bert import Bert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YycaUlL17829"
   },
   "outputs": [],
   "source": [
    "## gloabal variable for changing dataset.\n",
    "## data_name possible values: \"imdb\", \"medical\"\n",
    "data_name = \"imdb\"\n",
    "## num_classes possible values: \"imdb\"=2, \"medical\"=5\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the path for the training data sets, 5, 10, 25, and 50 per label\n",
    "data_path = 'data/'+data_name\n",
    "files = os.listdir(data_path)\n",
    "labeled_files = [data_path+\"/\"+file for file in files if \"train_labeled\" in file]\n",
    "\n",
    "## get the path for the test set\n",
    "test_path = data_path+\"/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IgGLg_kOxhg3"
   },
   "outputs": [],
   "source": [
    "# hyper parameters \n",
    "batch_size = 4\n",
    "seed = 0\n",
    "learning_rate = 5e-5\n",
    "epochs=5\n",
    "\n",
    "# create a data frame to store the results\n",
    "results=pd.DataFrame(columns=[\"n_per_class\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xITIE4h-5NO",
    "outputId": "05d1ac3a-8a14-45c8-adfe-aa60d6fb9df6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 16:06:22.949889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10800 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7\n",
      "2021-11-11 16:06:26.100253: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/imdb/train_labeled_5.csv\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 21s 261ms/step - loss: 0.8798 - accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 0.8023 - accuracy: 0.6000\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 0.8143 - accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 0.3634 - accuracy: 0.9000\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 1s 243ms/step - loss: 0.4016 - accuracy: 0.9000\n",
      "500/500 [==============================] - 18s 34ms/step - loss: 0.7131 - accuracy: 0.5780\n",
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n",
      "data/imdb/train_labeled_10.csv\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 21s 291ms/step - loss: 0.6899 - accuracy: 0.6500\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 1s 280ms/step - loss: 0.8311 - accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 1s 279ms/step - loss: 0.4144 - accuracy: 0.7500\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 1s 279ms/step - loss: 0.2541 - accuracy: 0.9500\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 1s 282ms/step - loss: 0.2200 - accuracy: 1.0000\n",
      "500/500 [==============================] - 18s 33ms/step - loss: 0.6528 - accuracy: 0.6360\n",
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n",
      "data/imdb/train_labeled_25.csv\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 24s 276ms/step - loss: 0.7634 - accuracy: 0.6200\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 4s 272ms/step - loss: 0.9393 - accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 4s 271ms/step - loss: 0.8266 - accuracy: 0.4400\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 4s 273ms/step - loss: 0.5808 - accuracy: 0.7600\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 4s 274ms/step - loss: 0.3491 - accuracy: 0.8200\n",
      "500/500 [==============================] - 17s 32ms/step - loss: 0.7582 - accuracy: 0.5700\n",
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n",
      "data/imdb/train_labeled_50.csv\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 27s 280ms/step - loss: 0.9254 - accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.6534 - accuracy: 0.6100\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 7s 279ms/step - loss: 0.3462 - accuracy: 0.8500\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 7s 279ms/step - loss: 0.1675 - accuracy: 0.9300\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1383 - accuracy: 0.9700\n",
      "500/500 [==============================] - 18s 32ms/step - loss: 1.0870 - accuracy: 0.7920\n"
     ]
    }
   ],
   "source": [
    "## train and evaluate bert for each data set. \n",
    "for n_per_class in [5,10,25,50]:\n",
    "    data_file = \"\"\n",
    "    result = {\"n_per_class\":n_per_class}\n",
    "    bert = Bert(num_classes = 2, random_state = seed) # create model \n",
    "    for file in labeled_files: ## find correct file\n",
    "        if f\"train_labeled_{n_per_class}.csv\" in file:\n",
    "            data_file = file\n",
    "            break\n",
    "    print(data_file)\n",
    "    ## train model\n",
    "    bert.train_from_path(data_file,learning_rate=learning_rate,batch_size=batch_size,epochs=epochs)\n",
    "    ## evaluate the model\n",
    "    performance = bert.evaluate_from_path(test_path)\n",
    "    ## add to resutl data frame\n",
    "    result[\"accuracy\"] = performance[1]\n",
    "    results = results.append(result,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "LZGVYA2GcoCU",
    "outputId": "8dc78616-4d26-4fa2-d406-41172b439228"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_per_class</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_per_class  accuracy\n",
       "0          5.0     0.578\n",
       "1         10.0     0.636\n",
       "2         25.0     0.570\n",
       "3         50.0     0.792"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print the result\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gZNtDZIgDXhw"
   },
   "outputs": [],
   "source": [
    "# write the result to file\n",
    "if not os.path.exists('results'):\n",
    "      os.mkdir('results')\n",
    "result_path = f'results/{data_name}'\n",
    "if not os.path.exists(result_path):\n",
    "      os.mkdir(result_path)\n",
    "results.to_csv(f\"{result_path}/bert_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
