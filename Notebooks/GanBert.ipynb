{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ddfdee5-c8dc-49d1-b59e-4f282a70e8f8",
   "metadata": {},
   "source": [
    "# Install dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9e0c45-7858-4388-b18d-0529fc12faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers==4.3.2\n",
    "\n",
    "!pip install -q torch\n",
    "\n",
    "!pip install -q numpy\n",
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358116d4-a9c8-4428-a775-7658c7355b28",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c82e5f-66ec-435c-aa0c-3e51e06b5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('..')\n",
    "from GanBert import GanBert\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3df28d-fce6-4bc4-a640-608d5288c7c2",
   "metadata": {},
   "source": [
    "# Set-up\n",
    "\n",
    "Set gloabal variable for changing dataset.\n",
    "\n",
    "Set data_name to the name of your dataset. This needs to correspond to a folder in /data/, which should be generated by the generate_data.ipynb notebook. num_classes manually needs to be set to the number of classes in your dataset.\n",
    "\n",
    "- data_name:\n",
    "    - \"imdb\"\n",
    "    - \"medical\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "604a699c-ca12-4187-888d-9da89cc1ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gloabal variable for changing dataset.\n",
    "## data_name possible values: \"imdb\", \"medical\"\n",
    "data_name = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4172092-a163-47be-a2be-3b06cfb379c1",
   "metadata": {},
   "source": [
    "## Get data\n",
    "- get the path for the labeled training data, 5, 10, 25, and 50 per label\n",
    "- get the path for the unlabeled training data, 5, 10, 25, and 50 per label\n",
    "- get the path for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "347b40c4-181a-4bb6-8b94-2fb21104b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## method for convcerting the dataset to the right format for the ganbert model\n",
    "def data_to_ganbert(data):    \n",
    "    data = list(zip(data.iloc[:,0],data.iloc[:,1]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85054513-f518-483a-8175-a2d5955ee548",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the path for the labeled training data, 5, 10, 25, and 50 per label\n",
    "data_path = 'data/'+data_name\n",
    "files = os.listdir(data_path)\n",
    "labeled_files = [data_path+\"/\"+file for file in files if \"train_labeled\" in file]\n",
    "\n",
    "## get the path for the unlabeled training data, 5, 10, 25, and 50 per label\n",
    "unlabeled = data_to_ganbert(pd.read_csv(f\"data/{data_name}/train_unlabeled.csv\"))\n",
    "\n",
    "## get the path for the test set\n",
    "test = data_to_ganbert(pd.read_csv(f\"data/{data_name}/test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac09310-e69d-4dd1-ae4d-b5b87f6ecda1",
   "metadata": {},
   "source": [
    "## Set hyper-parameters for Bert\n",
    "\n",
    "For more details, see https://github.com/crux82/ganbert-pytorch/blob/main/GANBERT_pytorch.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be86665a-06f8-42f9-b45c-33b1f07173bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters \n",
    "batch_size = 64\n",
    "max_seq_length = 128\n",
    "seed = 0\n",
    "learning_rate = 5e-5\n",
    "epochs=5\n",
    "\n",
    "# create a data frame to store the results\n",
    "results=pd.DataFrame(columns=[\"n_per_class\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401ff805-a4f5-43d5-bdb1-59dd6da76a79",
   "metadata": {},
   "source": [
    "# Traning and evalueate the Bert classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3903dfab-26a7-4d0f-8da5-894d4494eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla K80\n",
      "data/imdb/train_labeled_5.csv\n",
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.712\n",
      "  Average training loss discriminator: 1.096\n",
      "  Training epcoh took: 0:04:51\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.554\n",
      "  Test Loss: 1.283\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.717\n",
      "  Average training loss discriminator: 0.743\n",
      "  Training epcoh took: 0:04:52\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.513\n",
      "  Test Loss: 2.310\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.710\n",
      "  Average training loss discriminator: 0.725\n",
      "  Training epcoh took: 0:04:52\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.475\n",
      "  Test Loss: 2.994\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.704\n",
      "  Average training loss discriminator: 0.717\n",
      "  Training epcoh took: 0:04:52\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.491\n",
      "  Test Loss: 3.676\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.724\n",
      "  Average training loss discriminator: 0.775\n",
      "  Training epcoh took: 0:04:52\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.460\n",
      "  Test Loss: 2.204\n",
      "  Test took: 0:00:06\n",
      "{'epoch': 1, 'Training Loss generator': 0.7119819642622259, 'Training Loss discriminator': 1.0960854744609398, 'Valid. Loss': 1.2833571434020996, 'Valid. Accur.': 0.5535714285714286, 'Training Time': '0:04:51', 'Test Time': '0:00:06'}\n",
      "{'epoch': 2, 'Training Loss generator': 0.7174557507792606, 'Training Loss discriminator': 0.7432468322258962, 'Valid. Loss': 2.3098316192626953, 'Valid. Accur.': 0.5133928571428571, 'Training Time': '0:04:52', 'Test Time': '0:00:06'}\n",
      "{'epoch': 3, 'Training Loss generator': 0.7099787291092209, 'Training Loss discriminator': 0.7246469606327105, 'Valid. Loss': 2.994046926498413, 'Valid. Accur.': 0.47544642857142855, 'Training Time': '0:04:52', 'Test Time': '0:00:06'}\n",
      "{'epoch': 4, 'Training Loss generator': 0.7044691209551655, 'Training Loss discriminator': 0.7170016825953617, 'Valid. Loss': 3.675868511199951, 'Valid. Accur.': 0.49107142857142855, 'Training Time': '0:04:52', 'Test Time': '0:00:06'}\n",
      "{'epoch': 5, 'Training Loss generator': 0.7238796323160582, 'Training Loss discriminator': 0.7749454982673065, 'Valid. Loss': 2.204031467437744, 'Valid. Accur.': 0.45982142857142855, 'Training Time': '0:04:52', 'Test Time': '0:00:06'}\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:24:57 (h:mm:ss)\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla K80\n",
      "data/imdb/train_labeled_10.csv\n",
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.722\n",
      "  Average training loss discriminator: 1.471\n",
      "  Training epcoh took: 0:04:56\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.556\n",
      "  Test Loss: 0.812\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.726\n",
      "  Average training loss discriminator: 0.771\n",
      "  Training epcoh took: 0:04:56\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.569\n",
      "  Test Loss: 2.001\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.712\n",
      "  Average training loss discriminator: 0.727\n",
      "  Training epcoh took: 0:04:56\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.540\n",
      "  Test Loss: 2.653\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.705\n",
      "  Average training loss discriminator: 0.720\n",
      "  Training epcoh took: 0:04:56\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.529\n",
      "  Test Loss: 3.188\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.725\n",
      "  Average training loss discriminator: 0.899\n",
      "  Training epcoh took: 0:04:56\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.536\n",
      "  Test Loss: 1.131\n",
      "  Test took: 0:00:06\n",
      "{'epoch': 1, 'Training Loss generator': 0.7224615827202797, 'Training Loss discriminator': 1.470528133958578, 'Valid. Loss': 0.811656653881073, 'Valid. Accur.': 0.5558035714285714, 'Training Time': '0:04:56', 'Test Time': '0:00:06'}\n",
      "{'epoch': 2, 'Training Loss generator': 0.7262450441718101, 'Training Loss discriminator': 0.771352580934763, 'Valid. Loss': 2.0005719661712646, 'Valid. Accur.': 0.5691964285714286, 'Training Time': '0:04:56', 'Test Time': '0:00:06'}\n",
      "{'epoch': 3, 'Training Loss generator': 0.7118553824722766, 'Training Loss discriminator': 0.7269490599632263, 'Valid. Loss': 2.6528491973876953, 'Valid. Accur.': 0.5401785714285714, 'Training Time': '0:04:56', 'Test Time': '0:00:06'}\n",
      "{'epoch': 4, 'Training Loss generator': 0.7050322383642197, 'Training Loss discriminator': 0.7195300169289112, 'Valid. Loss': 3.188455104827881, 'Valid. Accur.': 0.5290178571428571, 'Training Time': '0:04:56', 'Test Time': '0:00:06'}\n",
      "{'epoch': 5, 'Training Loss generator': 0.7249089486896991, 'Training Loss discriminator': 0.8994853690266609, 'Valid. Loss': 1.1311206817626953, 'Valid. Accur.': 0.5357142857142857, 'Training Time': '0:04:56', 'Test Time': '0:00:06'}\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:25:17 (h:mm:ss)\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla K80\n",
      "data/imdb/train_labeled_25.csv\n",
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.721\n",
      "  Average training loss discriminator: 1.191\n",
      "  Training epcoh took: 0:05:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.757\n",
      "  Test Loss: 0.747\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.718\n",
      "  Average training loss discriminator: 0.737\n",
      "  Training epcoh took: 0:05:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.772\n",
      "  Test Loss: 1.075\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.706\n",
      "  Average training loss discriminator: 0.723\n",
      "  Training epcoh took: 0:05:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.763\n",
      "  Test Loss: 1.363\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.703\n",
      "  Average training loss discriminator: 0.715\n",
      "  Training epcoh took: 0:05:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.779\n",
      "  Test Loss: 1.537\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.713\n",
      "  Training epcoh took: 0:05:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.779\n",
      "  Test Loss: 1.702\n",
      "  Test took: 0:00:06\n",
      "{'epoch': 1, 'Training Loss generator': 0.7212110961355814, 'Training Loss discriminator': 1.1913668607793204, 'Valid. Loss': 0.7472875714302063, 'Valid. Accur.': 0.7566964285714286, 'Training Time': '0:05:03', 'Test Time': '0:00:06'}\n",
      "{'epoch': 2, 'Training Loss generator': 0.7183276647474708, 'Training Loss discriminator': 0.7373935980040852, 'Valid. Loss': 1.0752955675125122, 'Valid. Accur.': 0.7723214285714286, 'Training Time': '0:05:03', 'Test Time': '0:00:06'}\n",
      "{'epoch': 3, 'Training Loss generator': 0.706269845003035, 'Training Loss discriminator': 0.7226875649719704, 'Valid. Loss': 1.3633469343185425, 'Valid. Accur.': 0.7633928571428571, 'Training Time': '0:05:03', 'Test Time': '0:00:06'}\n",
      "{'epoch': 4, 'Training Loss generator': 0.7027249176327776, 'Training Loss discriminator': 0.7152827745530663, 'Valid. Loss': 1.53653883934021, 'Valid. Accur.': 0.7790178571428571, 'Training Time': '0:05:03', 'Test Time': '0:00:06'}\n",
      "{'epoch': 5, 'Training Loss generator': 0.7005977688766107, 'Training Loss discriminator': 0.712551779863311, 'Valid. Loss': 1.7023882865905762, 'Valid. Accur.': 0.7790178571428571, 'Training Time': '0:05:03', 'Test Time': '0:00:06'}\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:25:54 (h:mm:ss)\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla K80\n",
      "data/imdb/train_labeled_50.csv\n",
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.723\n",
      "  Average training loss discriminator: 1.462\n",
      "  Training epcoh took: 0:05:14\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.708\n",
      "  Test Loss: 0.709\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.720\n",
      "  Average training loss discriminator: 0.806\n",
      "  Training epcoh took: 0:05:14\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.772\n",
      "  Test Loss: 0.909\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.709\n",
      "  Average training loss discriminator: 0.722\n",
      "  Training epcoh took: 0:05:14\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.770\n",
      "  Test Loss: 1.135\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.703\n",
      "  Average training loss discriminator: 0.716\n",
      "  Training epcoh took: 0:05:14\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.775\n",
      "  Test Loss: 1.427\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.712\n",
      "  Training epcoh took: 0:05:14\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.777\n",
      "  Test Loss: 1.668\n",
      "  Test took: 0:00:06\n",
      "{'epoch': 1, 'Training Loss generator': 0.72266524960013, 'Training Loss discriminator': 1.4623899501912734, 'Valid. Loss': 0.7092293500900269, 'Valid. Accur.': 0.7075892857142857, 'Training Time': '0:05:14', 'Test Time': '0:00:06'}\n",
      "{'epoch': 2, 'Training Loss generator': 0.7200217408292434, 'Training Loss discriminator': 0.8060737196136923, 'Valid. Loss': 0.9086064100265503, 'Valid. Accur.': 0.7723214285714286, 'Training Time': '0:05:14', 'Test Time': '0:00:06'}\n",
      "{'epoch': 3, 'Training Loss generator': 0.7090009570121765, 'Training Loss discriminator': 0.7223047431777505, 'Valid. Loss': 1.1347030401229858, 'Valid. Accur.': 0.7700892857142857, 'Training Time': '0:05:14', 'Test Time': '0:00:06'}\n",
      "{'epoch': 4, 'Training Loss generator': 0.7030443212565254, 'Training Loss discriminator': 0.7164734672097599, 'Valid. Loss': 1.4273133277893066, 'Valid. Accur.': 0.7745535714285714, 'Training Time': '0:05:14', 'Test Time': '0:00:06'}\n",
      "{'epoch': 5, 'Training Loss generator': 0.7008448208079618, 'Training Loss discriminator': 0.712181629152859, 'Valid. Loss': 1.6677571535110474, 'Valid. Accur.': 0.7767857142857143, 'Training Time': '0:05:14', 'Test Time': '0:00:06'}\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:26:48 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "## train and evaluate bert for each data set. \n",
    "for n_per_class in [5,10,25,50]:\n",
    "    data_file = \"\"\n",
    "    result = {\"n_per_class\":n_per_class}\n",
    "    # create model\n",
    "    ganbert = GanBert(batch_size=batch_size,max_seq_length= max_seq_length,epochs = epochs,\n",
    "                      learning_rate_discriminator = learning_rate,learning_rate_generator = learning_rate,\n",
    "                      print_each_n_step = 100,random_state = seed)\n",
    "    ## find correct file\n",
    "    for file in labeled_files:\n",
    "        if f\"data/{data_name}/train_labeled_{n_per_class}.csv\" == file:\n",
    "            data_file = file\n",
    "            break\n",
    "    print(data_file)\n",
    "    labeled = data_to_ganbert(pd.read_csv(data_file))\n",
    "    ## train and evaluate the model\n",
    "    performance = ganbert.train(labeled,unlabeled, test)\n",
    "    ## add to resutl data frame\n",
    "    result[\"accuracy\"] = performance\n",
    "    results = results.append(result,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9761404-4642-4f4a-aae1-109f20e5f805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_per_class</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.459821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.779018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.776786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_per_class  accuracy\n",
       "0          5.0  0.459821\n",
       "1         10.0  0.535714\n",
       "2         25.0  0.779018\n",
       "3         50.0  0.776786"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print the result\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "045ada9e-fea5-4837-940e-7b48d8150f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the result to file\n",
    "if not os.path.exists('results'):\n",
    "      os.mkdir('results')\n",
    "result_path = f'results/{data_name}'\n",
    "if not os.path.exists(result_path):\n",
    "      os.mkdir(result_path)\n",
    "results.to_csv(f\"{result_path}/GanBert_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5098817-54fa-4c50-b3f9-1fd9f41f81ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
