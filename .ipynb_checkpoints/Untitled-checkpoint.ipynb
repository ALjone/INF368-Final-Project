{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python GPT2Tuner.py \\\n",
    "--train_data_path ./data/train_labeled_5.csv \\\n",
    "--output_name generated_samples_5.txt \\\n",
    "--output_dir ./data \\\n",
    "--epochs 10 \\\n",
    "--device cuda \\\n",
    "--samples_per_class 200\\\n",
    "--batch_size 1 \\\n",
    "--batch_size 1 \\\n",
    "--torch_seed 1 \\\n",
    "--numpy_seed 2 \\\n",
    "--random_seed 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python GPT2Tuner.py \\\n",
    "--train_data_path ./data/train_labeled_10.csv \\\n",
    "--output_name generated_samples_10.txt \\\n",
    "--output_dir ./data \\\n",
    "--epochs 10 \\\n",
    "--device cuda \\\n",
    "--samples_per_class 200\\\n",
    "--batch_size 1 \\\n",
    "--torch_seed 1 \\\n",
    "--numpy_seed 2 \\\n",
    "--random_seed 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python GPT2Tuner.py \\\n",
    "--train_data_path ./data/train_labeled_25.csv \\\n",
    "--output_name generated_samples_25.txt \\\n",
    "--output_dir ./data \\\n",
    "--epochs 10 \\\n",
    "--device cuda \\\n",
    "--samples_per_class 200\\\n",
    "--batch_size 1 \\\n",
    "--torch_seed 1 \\\n",
    "--numpy_seed 2 \\\n",
    "--random_seed 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python GPT2Tuner.py \\\n",
    "--train_data_path ./data/train_labeled_50.csv \\\n",
    "--output_name generated_samples_50.txt \\\n",
    "--output_dir ./data \\\n",
    "--device cuda \\\n",
    "--epochs 10 \\\n",
    "--device cuda \\\n",
    "--samples_per_class 200\\\n",
    "--batch_size 1 \\\n",
    "--torch_seed 1 \\\n",
    "--numpy_seed 2 \\\n",
    "--random_seed 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U tensorflow-text\n",
    "!pip install -q tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append(\"INF368-Final-Project\")\n",
    "from Bert import Bert\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = \"./data\"\n",
    "files = os.listdir(\"./data\")\n",
    "labeled_files = [data_path+\"/\"+file for file in files if \"train_labeled\" in file]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "seed = 0\n",
    "learning_rate = 5e-5\n",
    "epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n",
      "./data/train_labeled_25.csv\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 23s 275ms/step - loss: 0.8761 - accuracy: 0.5600\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 4s 271ms/step - loss: 1.0757 - accuracy: 0.4800\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 4s 271ms/step - loss: 0.8594 - accuracy: 0.3800\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 4s 273ms/step - loss: 0.6779 - accuracy: 0.6600\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 4s 272ms/step - loss: 0.6147 - accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_file = \"\"\n",
    "bert = Bert(num_classes = 2, random_state = seed)\n",
    "for file in labeled_files:\n",
    "    if f\"train_labeled_{25}.csv\" in file:\n",
    "        data_file = file\n",
    "        break\n",
    "print(data_file)\n",
    "bert.train_from_path(data_file,learning_rate=learning_rate,batch_size=batch_size,epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/generated_samples_25.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "gen = {\"text\": list(),\"label\" : list()}\n",
    "for line in lines:\n",
    "    gen[\"text\"].append(line[3:])\n",
    "    gen[\"label\"].append(line[:3])\n",
    "\n",
    "gen =pd.DataFrame(gen)\n",
    "conf = bert.predict_label_proba(gen.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>I saw this movie over the year. I had the mis...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.770941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The first episode of the video is actually go...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.759404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I like the movie and the way the movie takes ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.750932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>I was told that this movie was made in the 30...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.747723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>The only reason why this movie is so lame, is...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.746106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>I was just ready to move on to a different sc...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.745698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>The REAL question is this: a pointless movie ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.744483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>A classic movie, The Hot Spot for Murder. The...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.741398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I think that the movie was a bit of a rip-off...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.737948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't see the movie. I just saw it. It's no...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.736574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text label pred      conf\n",
       "141   I saw this movie over the year. I had the mis...   neg  neg  0.770941\n",
       "20    The first episode of the video is actually go...   neg  neg  0.759404\n",
       "31    I like the movie and the way the movie takes ...   neg  neg  0.750932\n",
       "83    I was told that this movie was made in the 30...   neg  neg  0.747723\n",
       "89    The only reason why this movie is so lame, is...   neg  neg  0.746106\n",
       "144   I was just ready to move on to a different sc...   neg  neg  0.745698\n",
       "291   The REAL question is this: a pointless movie ...   pos  neg  0.744483\n",
       "167   A classic movie, The Hot Spot for Murder. The...   neg  neg  0.741398\n",
       "42    I think that the movie was a bit of a rip-off...   neg  neg  0.737948\n",
       "2     I don't see the movie. I just saw it. It's no...   neg  neg  0.736574"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen[\"pred\"] = [label for label, prob in conf]\n",
    "gen[\"conf\"] = [prob for label, prob in conf]\n",
    "gen_sub= gen[gen.text.apply(lambda x: len(str(x))>10)].sort_values(\"conf\", ascending=False).head(10)\n",
    "gen_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(gen_sub.label ==gen_sub.pred)/len(gen_sub.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data = pd.read_csv(data_file)\n",
    "comb_data = pd.concat([data,gen_sub.loc[:,[\"text\",\"label\"]]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n",
      "Epoch 1/5\n",
      "15/15 [==============================] - 28s 282ms/step - loss: 0.8257 - accuracy: 0.4833\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 4s 278ms/step - loss: 0.4927 - accuracy: 0.6833\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 4s 280ms/step - loss: 0.2533 - accuracy: 0.8667\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 4s 279ms/step - loss: 0.0547 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 4s 279ms/step - loss: 0.0400 - accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "bert = Bert(num_classes = 2, random_state = seed)\n",
    "\n",
    "bert.train(comb_data.text,comb_data.label, learning_rate=learning_rate,batch_size=batch_size,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 18s 33ms/step - loss: 0.9016 - accuracy: 0.7240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.90159672498703, 0.7239999771118164]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.evaluate_from_path(data_path+\"/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 23s 275ms/step - loss: 0.8456 - accuracy: 0.5800\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 4s 270ms/step - loss: 1.0474 - accuracy: 0.4800\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 4s 271ms/step - loss: 0.8633 - accuracy: 0.3600\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 4s 272ms/step - loss: 0.7050 - accuracy: 0.6000\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 4s 271ms/step - loss: 0.6240 - accuracy: 0.7200\n",
      "500/500 [==============================] - 17s 32ms/step - loss: 0.6548 - accuracy: 0.5940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6547513604164124, 0.593999981880188]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = Bert(num_classes = 2, random_state = seed)\n",
    "\n",
    "bert.train_from_path(data_file, learning_rate=learning_rate,batch_size=batch_size,epochs=epochs)\n",
    "bert.evaluate_from_path(data_path+\"/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
